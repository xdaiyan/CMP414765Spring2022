{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week11_ImageClassification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPThgHfMGoaGAOuQGeRJiBT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Spring2022/blob/main/Week11_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwszdj54lJYI"
      },
      "source": [
        "# Week 11\n",
        "# Image Classification with Convolutional Neural Network (CNN)\n",
        "\n",
        "**Reference:** [TensorFlow Tutorial on Convolutional Neural Networks](https://www.tensorflow.org/tutorials/images/cnn)\n",
        "\n",
        "**Please enable GPU computing before proceed.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlP21Dd3lUmQ"
      },
      "source": [
        "### Ideas\n",
        "- Dense layers may contain redudent connections\n",
        "- Some information should be invariant to spacial translation\n",
        "- The number of parameters can be reduced if certain weights share the same value.\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcS4LZdFg5QPbgDb-jvP-YT0N51eRkWg45uF0ybsB5k0Ubr0-gOC&usqp=CAU\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUdECNflUqJ"
      },
      "source": [
        "## 2D Convolution Layer\n",
        "<img src=\"https://cdn-media-1.freecodecamp.org/images/Gjxh-aApWTzIRI1UNmGnNLrk8OKsQaf2tlDu\" width=\"600\">\n",
        "\n",
        "**Comparison:**\n",
        "If this were a densely connect layer:\n",
        "- The number of connection would be: 64 * 64 = 4096\n",
        "- The number of weight parameters would be: 4096\n",
        "\n",
        "Now that this is a convolutional layer (with a 3*3 filter):\n",
        "- The number of connection is: 9 * 64 = 576\n",
        "- The number of parameters is: 9\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwW4aozplUsh"
      },
      "source": [
        "**2D smoothing with Gaussian kernel**\n",
        "\n",
        "<img src=\"https://www.cs.umd.edu/class/fall2016/cmsc426/matlab/filters/html/filters_tutorial_03.png\" width=\"600\">\n",
        "\n",
        "<img src=\"https://www.mathworks.com/help/examples/stats/win64/ComputeTheMultivariateNormalPdfExample_01.png\" width=\"400\">\n",
        "\n",
        "**Edge detection**\n",
        "\n",
        "<img src=\"https://media5.datahacker.rs/2018/10/edges.jpg\" width=\"600\">\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Ching-Wei_Wang/publication/221472523/figure/fig5/AS:305540338077700@1449857901164/Convolution-filter-for-simple-edge-detect.png\" width=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLjGZkvdlUuv"
      },
      "source": [
        "## LeNet5 on MNIST\n",
        "\n",
        "Yann LeCun, Leon Bottou, Yosuha Bengio and Patrick Haffner proposed a neural network architecture for handwritten and machine-printed character recognition in 1990â€™s which they called LeNet-5. It is one of the early example of a convolutional neural network\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBDLWUMXlUxd"
      },
      "source": [
        "## Max-Pooling Layer\n",
        "<img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3NwmG7lUz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8f59bd-ff1a-4965-83e6-268ad7e225a1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK6gaIZllU22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477250fd-152e-420a-dd23-14721a6d7991"
      },
      "source": [
        "# Load and prepare the MNIST dataset.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert the data from integers to floating-point numbers\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mlo6L7WlU4_"
      },
      "source": [
        "model_cnn = tf.keras.models.Sequential()\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Conv2D(filters=6,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(28, 28, 1)))\n",
        "\n",
        "model_cnn.add(tf.keras.layers.MaxPooling2D())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Conv2D(filters=16,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 activation='relu'))\n",
        "\n",
        "model_cnn.add(tf.keras.layers.MaxPooling2D())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Dense(units=120,\n",
        "                       activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dense(units=84,\n",
        "                       activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dense(units=10,\n",
        "                       activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k4KnhA7lU7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f498e9-cc80-44d0-b3a4-f89e10f69839"
      },
      "source": [
        "model_cnn.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9uUBdPlU9z"
      },
      "source": [
        "model_cnn.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), # (from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJPG5htRlVAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066756c7-40d7-4fd2-e0ce-9b779beedf72"
      },
      "source": [
        "model_cnn.fit(x_train.reshape(list(x_train.shape) + [1]), y_train, epochs=10, validation_split=0.1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 18s 5ms/step - loss: 0.2087 - accuracy: 0.9367 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0676 - accuracy: 0.9797 - val_loss: 0.0610 - val_accuracy: 0.9810\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0487 - val_accuracy: 0.9865\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.0376 - val_accuracy: 0.9888\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.0436 - val_accuracy: 0.9878\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0447 - val_accuracy: 0.9882\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0436 - val_accuracy: 0.9887\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0435 - val_accuracy: 0.9887\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0624 - val_accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0483 - val_accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3b0195450>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDHmNAYTlVC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da55453c-a225-48dc-c22b-b3199ba3dd4e"
      },
      "source": [
        "model_cnn.evaluate(x_test.reshape(list(x_test.shape) + [1]), y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.9885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.039080433547496796, 0.9884999990463257]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82mo08SBlVFg"
      },
      "source": [
        "## Dropout and Model Regularization\n",
        "For a complicated model like deep neural networks, a major concern on its performance is model overfitting:\n",
        "\n",
        "![underfitting and overfitting](https://cdn-images-1.medium.com/max/1200/1*cdvfzvpkJkUudDEryFtCnA.png)\n",
        "\n",
        "In plain words, overfitting happens when the model is **memorizing** the training data, and become poorly at **generalizing** what they've learned to unseen data. Think about a student who memorized the entire machine learning textbook. He may appear quite knowledgable in machine learning when asked things directly from the book, but there is no way he can perform a machine project on a dataset not mentioned in the book.\n",
        "\n",
        "### How to dentify model overfitting?\n",
        "- Visualize the model (decision boundary, regression curves, etc.)\n",
        "- Observe the trends in training loss and the testing loss\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*vuZxFMi5fODz2OEcpG-S1g.png)\n",
        "\n",
        "### How to prevent model overfitting?\n",
        "1. Start with a simple model\n",
        "\n",
        "![](https://image.slidesharecdn.com/lawsofwebdesign-091104020153-phpapp01/95/laws-of-web-development-11-728.jpg?cb=1257384621)\n",
        "2. Add penalty to complicated models\n",
        "    - L1 Regularizor\n",
        "    - L2 Regularizor\n",
        "    - Elastic Net\n",
        "\n",
        "3. (For Neural Networks) Dropout layers: remove weights to the next layer\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1800/1*iWQzxhVlvadk6VAJjsgXgg.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7C9uja3lVIo"
      },
      "source": [
        "# Image Classification with CIFAR-10 Dataset\n",
        "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is a widely used benchmark dataset for image classifiers. The dataset consists of 10 classes of color images of size $32\\times 32$. Let's build a neural network with **convolutional layers** to classify the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfGOVAjClVLW"
      },
      "source": [
        "### Download the dataset\n",
        "- Use `request` to download the tar file from [https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)\n",
        "- Use `tarfile` to extract files\n",
        "- Use `pickle` to load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvd_rMKylVOV",
        "outputId": "8f150bbf-fdae-4ad9-fd69-f18999c723ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import requests\n",
        "\n",
        "filename = \"cifar-10-python.tar.gz\"\n",
        "if not os.path.isfile(filename):\n",
        "    print(\"Downloading CIFAR10 dataset...\")\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    file = requests.get(url)\n",
        "\n",
        "    print(\"Writing to file\", filename, \"...\")\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(file.content)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CIFAR10 dataset...\n",
            "Writing to file cifar-10-python.tar.gz ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG81Rh39njsY",
        "outputId": "d075379f-85e1-4ad4-ce52-aea71fc5455d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tarfile\n",
        "datapath = \"cifar-10-batches-py/\" \n",
        "if not os.path.isdir(datapath):\n",
        "    print(\"Extracting files...\")\n",
        "    tar = tarfile.open(filename)\n",
        "    tar.extractall()\n",
        "    print(\"Files extracted.\")\n",
        "    tar.close()\n",
        "os.listdir(datapath)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Files extracted.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_batch_2',\n",
              " 'data_batch_5',\n",
              " 'data_batch_4',\n",
              " 'readme.html',\n",
              " 'test_batch',\n",
              " 'data_batch_3',\n",
              " 'data_batch_1',\n",
              " 'batches.meta']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4qtN_Kwnkz2",
        "outputId": "eabbc790-bf2a-4724-fb8e-ab981e0195b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load one batch\n",
        "import pickle\n",
        "with open(datapath + \"data_batch_1\", \"rb\") as f:\n",
        "    batch = pickle.load(f, encoding=\"latin1\")\n",
        "    features = batch['data'].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "print(\"feature size:\", features.shape)\n",
        "print(\"label size:\", len(labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature size: (10000, 32, 32, 3)\n",
            "label size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-O9uujRnmGr"
      },
      "source": [
        "The label data is just a list of 10000 numbers in the range 0-9, which corresponds to each of the 10 classes in CIFAR-10. \n",
        "\n",
        "* **airplane**\n",
        "* **automobile**\n",
        "* **bird**\n",
        "* **cat**\n",
        "* **deer**\n",
        "* **dog**\n",
        "* **frog**\n",
        "* **horse**\n",
        "* **ship**\n",
        "* **truck**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvXzwOgnn7y",
        "outputId": "fed2e35b-907b-4639-ab37-0a1167c325dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# Show a sample image\n",
        "sample_id = 4321\n",
        "plt.imshow(features[sample_id])\n",
        "label_names = ['airplane', 'automobile', 'bird',\n",
        "            'cat', 'deer', 'dog', 'frog',\n",
        "            'horse', 'ship', 'truck']\n",
        "plt.xlabel(label_names[labels[sample_id]])\n",
        "# labels[sample_id]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'truck')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_2nNz8CnpN6",
        "outputId": "092d2503-767e-4b9b-9a55-e3735d05685f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load all images from batch 1-5\n",
        "train_features = np.empty([0, 32, 32, 3], dtype=np.uint8)\n",
        "train_labels = np.empty([0])\n",
        "for k in range(1, 6):\n",
        "    with open(datapath + \"data_batch_\" + str(k), \"rb\") as f:\n",
        "        batch = pickle.load(f, encoding=\"latin1\")\n",
        "        features = batch[\"data\"].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
        "        labels=batch['labels']\n",
        "        print(\"features shape:\", features.shape)\n",
        "        print(\"labels shape:\", len(labels))\n",
        "        train_features = np.append(train_features, features, axis=0)\n",
        "        train_labels = np.append(train_labels, labels, axis=0)\n",
        "print(\"train_features shape:\", train_features.shape)\n",
        "print(\"train_labels shape:\", train_labels.shape)\n",
        "        "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "features shape: (10000, 32, 32, 3)\n",
            "labels shape: 10000\n",
            "train_features shape: (50000, 32, 32, 3)\n",
            "train_labels shape: (50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xay2mi6LnrEq"
      },
      "source": [
        "## Build CNN model\n",
        "### Create Convolutional Model\n",
        "\n",
        "The entire model consists of 14 layers in total. In addition to layers below lists what techniques are applied to build the model.\n",
        "\n",
        "1. Convolution with 32 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "2. Convolution with 32 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "    - Max Pooling by 2\n",
        "    - Dropout \n",
        "3. Convolution with 64 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "4. Convolution with 64 different filters in size of (3x3)\n",
        "    - ReLU activation function \n",
        "    - Max Pooling by 2\n",
        "    - Dropout \n",
        "5. Flattening the 3-D output of the last convolutional operations.\n",
        "6. Fully Connected Layer with 512 units\n",
        "  - Dropout \n",
        "7. Fully Connected Layer with 10 units (number of image classes)\n",
        "\n",
        "the image below decribes how the conceptual convolving operation differs from the tensorflow implementation when you use [Channel x Width x Height] tensor format. \n",
        "\n",
        "<img src=\"https://adeshpande3.github.io/assets/Cover.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo9fxr9Vntda"
      },
      "source": [
        "batch_size = 32 # How many images to load at a time\n",
        "num_classes = 10 \n",
        "epochs = 10\n",
        "num_predictions = 20"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKz3Lr-3aSxq",
        "outputId": "6fea0b0f-7396-4bff-8809-406ec39442a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The number of training iterations:\n",
        "50000 / 32 * 10"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15625.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtFtokyrnvob"
      },
      "source": [
        "# Build CNN model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
        "                              input_shape=features[0].shape, # (32, 32, 3)\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
        "                              activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
        "model.add(tf.keras.layers.Dense(num_classes))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rYxSeG_dBft",
        "outputId": "943c2ca1-3596-48bd-eee1-abc908b859d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# How can I print the list of layers?\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,168,362\n",
            "Trainable params: 2,168,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69mjsLBtnwrM"
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJxxUhQ8nx3h"
      },
      "source": [
        "# Normalize data\n",
        "def normalize(x):\n",
        "    \"\"\"\n",
        "        argument\n",
        "            - x: input image data in numpy array [32, 32, 3]\n",
        "        return\n",
        "            - normalized x \n",
        "    \"\"\"\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    x = (x-min_val) / (max_val-min_val)\n",
        "    return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGj02QVnnze3"
      },
      "source": [
        "train_features_scaled = normalize(train_features)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_euMmmhRn0u6",
        "outputId": "db1697d0-9533-4686-ad85-5276fe660ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history =  model.fit(train_features_scaled, train_labels, epochs=10, batch_size=batch_size)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 20s 12ms/step - loss: 1.4687 - accuracy: 0.4628\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.0801 - accuracy: 0.6150\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.9235 - accuracy: 0.6748\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8290 - accuracy: 0.7075\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7681 - accuracy: 0.7328\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7079 - accuracy: 0.7535\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6669 - accuracy: 0.7630\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6307 - accuracy: 0.7802\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5984 - accuracy: 0.7905\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5650 - accuracy: 0.8029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViXUTJNRn1o7",
        "outputId": "39f92b6e-d019-4251-f109-ea695c4218cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# Evaluate the model\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy') # allocate validation data to get val_accuracy\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff2cbe3a110>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N3j3Jxsn3Tr"
      },
      "source": [
        "# Load test images\n",
        "with open(datapath + \"test_batch\", \"rb\") as f:\n",
        "    batch = pickle.load(f, encoding=\"latin1\")\n",
        "    test_features = batch['data'].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0tEPxnn4qT"
      },
      "source": [
        "# Normalize test features\n",
        "test_features_scaled = normalize(test_features)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0l6WS3gn5nX",
        "outputId": "68f4bcde-3c72-491d-e6dd-27a2d279b893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_labels = np.array(test_labels)\n",
        "test_labels.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrK66WvJn6ig",
        "outputId": "b3be9bb5-1d9f-4e09-ce41-d71007ff6616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_features_scaled,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - loss: 0.6643 - accuracy: 0.7775 - 2s/epoch - 6ms/step\n",
            "0.7774999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "test_predictions = model(test_features_scaled)"
      ],
      "metadata": {
        "id": "q9cUtAQmjsK9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", test_predictions.shape)\n",
        "print(\"First prediction (logits):\", test_predictions[0])\n",
        "print(\"First prediction (probabilities):\", tf.nn.softmax(test_predictions[0]))\n",
        "print(\"First prediction (class):\", np.argmax(tf.nn.softmax(test_predictions[0])))\n",
        "# confusion_matrix(test_labels, )"
      ],
      "metadata": {
        "id": "I1pMeJ-_kNUv",
        "outputId": "2a3319a3-46df-423f-e957-fad3ab102a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (10000, 10)\n",
            "First prediction (logits): tf.Tensor(\n",
            "[-2.6860275 -1.9911957 -1.7169613  4.3345804 -6.5999465  3.741887\n",
            "  0.8238385 -3.9753628 -0.5053565 -3.9556954], shape=(10,), dtype=float32)\n",
            "First prediction (probabilities): tf.Tensor(\n",
            "[5.5964093e-04 1.1211690e-03 1.4749236e-03 6.2649953e-01 1.1171623e-05\n",
            " 3.4635168e-01 1.8716512e-02 1.5415525e-04 4.9540792e-03 1.5721712e-04], shape=(10,), dtype=float32)\n",
            "First prediction (class): 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9nTByB0UlwsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_labels = []\n",
        "for ind in range(10000):\n",
        "    pred = np.argmax(tf.nn.softmax(test_predictions[ind]))\n",
        "    test_predictions_labels.append(pred)\n",
        "print(test_predictions_labels[:10])"
      ],
      "metadata": {
        "id": "_bV-tDQXlLMU",
        "outputId": "efc78c49-e344-4ad3-9229-f980cdc70059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 8, 8, 0, 6, 6, 1, 6, 3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_labels, test_predictions_labels)"
      ],
      "metadata": {
        "id": "Mi_2hzMpl7tZ",
        "outputId": "4421c47b-8d18-43ad-ad74-79879a79a18b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[789,  12,  37,  23,   9,   0,   8,  12,  88,  22],\n",
              "       [  9, 915,   1,   5,   1,   1,   8,   1,  23,  36],\n",
              "       [ 56,   5, 593,  59,  72,  53, 102,  29,  24,   7],\n",
              "       [ 18,  11,  54, 612,  40, 119,  84,  34,  18,  10],\n",
              "       [ 16,   4,  32,  67, 707,  23,  83,  53,  13,   2],\n",
              "       [  9,   4,  31, 174,  30, 664,  31,  38,  12,   7],\n",
              "       [  5,   5,  19,  49,   9,   9, 894,   4,   6,   0],\n",
              "       [ 11,   4,  23,  30,  31,  41,   8, 838,   5,   9],\n",
              "       [ 23,  19,   4,   4,   5,   4,   2,   4, 920,  15],\n",
              "       [ 17,  83,   2,  10,   4,   2,   4,   7,  28, 843]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tPiRhSCn7mN"
      },
      "source": [
        "## Addition Discussion: What if we train a dense neural network instead?\n",
        "\n",
        "- Mimic the approach we took in the first neural network example.\n",
        "- Be aware that each color image is represented as a 3D array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QUtqcxfgdEP"
      },
      "source": [
        "# How to evaluate the model in other measures?\n",
        "- Confusion matrix\n",
        "- Cross validation: \n",
        "    - Currently: training: batch 1 - 5, test: test_batch\n",
        "    - Another test: training: batch 1, 2, 3, 4 and test_batch, test: batch 5\n",
        "    - Another test: training: batch 1, 2, 3, 5, and test_batch, test: batch 4\n",
        "    - ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-inbVVTgw6c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}